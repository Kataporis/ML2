{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4332272,"sourceType":"datasetVersion","datasetId":2548693}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Setup","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-08T01:30:42.684438Z","iopub.execute_input":"2024-04-08T01:30:42.684892Z","iopub.status.idle":"2024-04-08T01:30:42.695416Z","shell.execute_reply.started":"2024-04-08T01:30:42.684859Z","shell.execute_reply":"2024-04-08T01:30:42.694318Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"/kaggle/input/quotes-by-philosophers/Plato.txt\n/kaggle/input/quotes-by-philosophers/Immanuel-Kant.txt\n/kaggle/input/quotes-by-philosophers/Arthur-Schopenhauer-Quotes.txt\n/kaggle/input/quotes-by-philosophers/Jean-Paul-Sartre.txt\n/kaggle/input/quotes-by-philosophers/Spinoza.txt\n/kaggle/input/quotes-by-philosophers/Sigmund-Freud.txt\n/kaggle/input/quotes-by-philosophers/Aristotle.txt\n/kaggle/input/quotes-by-philosophers/Friedrich-Nietzsche.txt\n/kaggle/input/quotes-by-philosophers/Hegel.txt\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Import the necessary libraries.","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing import sequence\nimport keras\nimport tensorflow as tf\nimport os\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.698343Z","iopub.execute_input":"2024-04-08T01:30:42.699290Z","iopub.status.idle":"2024-04-08T01:30:42.705187Z","shell.execute_reply.started":"2024-04-08T01:30:42.699257Z","shell.execute_reply":"2024-04-08T01:30:42.704375Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"markdown","source":"The Kaggle dataset contains quotes from famous philosophers, as follows:\nArthur Schopenhauer 400+ quotes\nFriedrich Nietzsche 200+ quotes\nImmanuel Kant 300+ quotes\nAristotle 350+ quotes\nPlato 70+ quotes\nSigmund Freud 400+ quotes\nHegel 120+ quotes\nJean Paul Sartre 320+ quotes\nSpinoza 120+ quotes\n(Bozkurt, 2022).\n\nI chose to focus on Arthur Schopenhauer's quotes, since there was plenty of data to work with.","metadata":{}},{"cell_type":"markdown","source":"First, it is necessary to import the dataset. The 'unicode_escape' encoding is crucial for working with this data, since there are Unicode characters that may have been escaped in the file. It can then be decoded back into a string.","metadata":{}},{"cell_type":"code","source":"path = \"../input/quotes-by-philosophers/Arthur-Schopenhauer-Quotes.txt\"\ntext = open(path, 'rb').read().decode(encoding='unicode_escape')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.706326Z","iopub.execute_input":"2024-04-08T01:30:42.706911Z","iopub.status.idle":"2024-04-08T01:30:42.714514Z","shell.execute_reply.started":"2024-04-08T01:30:42.706861Z","shell.execute_reply":"2024-04-08T01:30:42.713574Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"markdown","source":"Now, a sample of the text can be printed to ensure the decoding process went smoothly and get a better idea of how the text looks in general before preprocessing.","metadata":{}},{"cell_type":"code","source":"print(text[:240])","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.715586Z","iopub.execute_input":"2024-04-08T01:30:42.715870Z","iopub.status.idle":"2024-04-08T01:30:42.721392Z","shell.execute_reply.started":"2024-04-08T01:30:42.715848Z","shell.execute_reply":"2024-04-08T01:30:42.720442Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"It is difficult to find happiness within oneself, but it is impossible to find it anywhere else.\nAll truth passes through three stages. First, it is ridiculed. Second, it is violently opposed. Third, it is accepted as being self-evident.\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now it is necessary to build the vocabulary of the text. This vocabulary will be the set of all unique characters in the text in ascending order.","metadata":{}},{"cell_type":"code","source":"vocab = sorted(set(text))\nprint(f'{len(vocab)} unique characters')","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.723789Z","iopub.execute_input":"2024-04-08T01:30:42.724039Z","iopub.status.idle":"2024-04-08T01:30:42.731287Z","shell.execute_reply.started":"2024-04-08T01:30:42.724018Z","shell.execute_reply":"2024-04-08T01:30:42.730394Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"75 unique characters\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Converting characters to numbers is one of the most important steps for building a RNN to work on a text dataset. This is because neural networks can only work with numerical data. The next step is therefore to convert characters to numbers:","metadata":{}},{"cell_type":"code","source":"words = sorted(set(text))\n\nchar2idx = {u:i for i, u in enumerate(words)}\nidx2char = np.array(words)\n\ndef text2num(text):\n  return np.array([char2idx[c] for c in text])\n  \nnum_text = text2num(text)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.732286Z","iopub.execute_input":"2024-04-08T01:30:42.732571Z","iopub.status.idle":"2024-04-08T01:30:42.751725Z","shell.execute_reply.started":"2024-04-08T01:30:42.732549Z","shell.execute_reply":"2024-04-08T01:30:42.750943Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"Later on, it will also be necessary to convert back to text, so the following function can take care of that:","metadata":{}},{"cell_type":"code","source":"def num2text(nums):\n  try:\n    nums = nums.numpy()\n  except:\n    pass\n  return ''.join(idx2char[nums])","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.752843Z","iopub.execute_input":"2024-04-08T01:30:42.753143Z","iopub.status.idle":"2024-04-08T01:30:42.760025Z","shell.execute_reply.started":"2024-04-08T01:30:42.753122Z","shell.execute_reply":"2024-04-08T01:30:42.759144Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"markdown","source":"# Prepare for Training","metadata":{}},{"cell_type":"markdown","source":"The data can now be prepared for the specific task of text generation from sequences of characters. The goal is to utilize the data for a sequence-to-sequence model in order to predict the next character in a sequence.","metadata":{}},{"cell_type":"code","source":"seq_length = 100  \nexamples_per_epoch = len(text)//(seq_length+1)\nchar_dataset = tf.data.Dataset.from_tensor_slices(num_text)\nsequences = char_dataset.batch(seq_length+1, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.761258Z","iopub.execute_input":"2024-04-08T01:30:42.761680Z","iopub.status.idle":"2024-04-08T01:30:42.772812Z","shell.execute_reply.started":"2024-04-08T01:30:42.761633Z","shell.execute_reply":"2024-04-08T01:30:42.771983Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"def split_input_target(chunk):\n    input_text = chunk[:-1]  \n    target_text = chunk[1:] \n    return input_text, target_text\ndataset = sequences.map(split_input_target)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.773904Z","iopub.execute_input":"2024-04-08T01:30:42.774165Z","iopub.status.idle":"2024-04-08T01:30:42.827991Z","shell.execute_reply.started":"2024-04-08T01:30:42.774144Z","shell.execute_reply":"2024-04-08T01:30:42.827266Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"markdown","source":"Now the training batches can be allocated accordingly and the training parameters specified. I set the EMBEDDING_DIM to 100 to start with, since it can be relative small for models such as this one. I initially specified a batch size, but kept encountering errors, so I chose to omit it.","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64\nVOCAB_SIZE = len(words) \nEMBEDDING_DIM = 100\nRNN_UNITS = 1024\n\nBUFFER_SIZE = 10000\n\ndata = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.829091Z","iopub.execute_input":"2024-04-08T01:30:42.829410Z","iopub.status.idle":"2024-04-08T01:30:42.836400Z","shell.execute_reply.started":"2024-04-08T01:30:42.829380Z","shell.execute_reply":"2024-04-08T01:30:42.835444Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"markdown","source":"# Building the Model","metadata":{}},{"cell_type":"markdown","source":"Built the model using two LSTM layers*, one embedding layer, a dropout layer for regularization, and a Dense output layer to predict the next character in the sequence. After encountering many errors, I had to resort to just one LSTM layer, after all. I also encountered some errors related to the input shape of the embedding layer. I was able to avoid the error by explicitly statingt the input, but I believe that may have altered my results down the line. I may be misunderstaing how things are supposed to work there.","metadata":{}},{"cell_type":"code","source":"model = tf.keras.Sequential([\n    tf.keras.layers.Input(shape=(None,)),\n    tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM),\n    tf.keras.layers.LSTM(RNN_UNITS,\n                         return_sequences=True),\n    tf.keras.layers.Dropout(0.2),\n    # tf.keras.layers.LSTM(RNN_UNITS),\n    tf.keras.layers.Dense(VOCAB_SIZE)\n])","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:42.837616Z","iopub.execute_input":"2024-04-08T01:30:42.837959Z","iopub.status.idle":"2024-04-08T01:30:43.855904Z","shell.execute_reply.started":"2024-04-08T01:30:42.837933Z","shell.execute_reply":"2024-04-08T01:30:43.854879Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"markdown","source":"Then, compile the model. Specify the adam optimizer without a learning rate and a sparse categorical crossentropy loss function in order to output a proabibility distribution for the possible characters.","metadata":{}},{"cell_type":"code","source":"loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n\nmodel.compile(optimizer='adam', loss=loss)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:43.857172Z","iopub.execute_input":"2024-04-08T01:30:43.857463Z","iopub.status.idle":"2024-04-08T01:30:43.865441Z","shell.execute_reply.started":"2024-04-08T01:30:43.857440Z","shell.execute_reply":"2024-04-08T01:30:43.864684Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"# Train the Model","metadata":{}},{"cell_type":"markdown","source":"First, configure a custom callback with checkpoints to avoid having to retrain from scratch.","metadata":{}},{"cell_type":"code","source":"checkpoint_dir = './training_checkpoints'\n\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n\ncheckpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_prefix,\n    save_weights_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:43.866659Z","iopub.execute_input":"2024-04-08T01:30:43.867020Z","iopub.status.idle":"2024-04-08T01:30:43.873599Z","shell.execute_reply.started":"2024-04-08T01:30:43.866994Z","shell.execute_reply":"2024-04-08T01:30:43.872849Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"markdown","source":"Then, training can finally commence over 100 epochs. After experiencing some weird generated text, I decided to up this number to 150:","metadata":{}},{"cell_type":"code","source":"history = model.fit(data, epochs=150, callbacks=[checkpoint_callback])","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:30:43.876862Z","iopub.execute_input":"2024-04-08T01:30:43.877224Z","iopub.status.idle":"2024-04-08T01:33:04.361466Z","shell.execute_reply.started":"2024-04-08T01:30:43.877198Z","shell.execute_reply":"2024-04-08T01:33:04.360491Z"},"trusted":true},"execution_count":57,"outputs":[{"name":"stdout","text":"Epoch 1/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 85ms/step - loss: 4.1256\nEpoch 2/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 3.1395\nEpoch 3/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 3.0239\nEpoch 4/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 2.9384\nEpoch 5/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 2.8431\nEpoch 6/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.7216\nEpoch 7/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - loss: 2.6106\nEpoch 8/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 2.5447\nEpoch 9/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.4860\nEpoch 10/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.4247\nEpoch 11/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 2.3859\nEpoch 12/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.3370\nEpoch 13/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.3051\nEpoch 14/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 95ms/step - loss: 2.2714\nEpoch 15/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.2377\nEpoch 16/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.2113\nEpoch 17/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 2.1795\nEpoch 18/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.1477\nEpoch 19/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.1277\nEpoch 20/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 2.0884\nEpoch 21/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 2.0751\nEpoch 22/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 2.0440\nEpoch 23/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 2.0265\nEpoch 24/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 2.0068\nEpoch 25/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 1.9720\nEpoch 26/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.9584\nEpoch 27/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 1.9140\nEpoch 28/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 1.9092\nEpoch 29/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - loss: 1.8760\nEpoch 30/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 1.8498\nEpoch 31/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.8324\nEpoch 32/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 1.8228\nEpoch 33/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 1.7942\nEpoch 34/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 1.7587\nEpoch 35/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 1.7454\nEpoch 36/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 1.7229\nEpoch 37/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.7081\nEpoch 38/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 1.6761\nEpoch 39/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.6586\nEpoch 40/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 1.6468\nEpoch 41/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.6340\nEpoch 42/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 1.6027\nEpoch 43/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 1.5741\nEpoch 44/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 1.5672\nEpoch 45/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 1.5374\nEpoch 46/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.5292\nEpoch 47/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 1.4998\nEpoch 48/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 1.4818\nEpoch 49/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.4696\nEpoch 50/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.4532\nEpoch 51/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.4427\nEpoch 52/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.3994\nEpoch 53/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 1.3828\nEpoch 54/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 1.3619\nEpoch 55/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.3448\nEpoch 56/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.3185\nEpoch 57/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.2996\nEpoch 58/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.2795\nEpoch 59/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.2618\nEpoch 60/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.2403\nEpoch 61/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.2181\nEpoch 62/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 1.1912\nEpoch 63/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 1.1657\nEpoch 64/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 1.1421\nEpoch 65/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 1.1156\nEpoch 66/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 1.0808\nEpoch 67/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 1.0661\nEpoch 68/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 1.0235\nEpoch 69/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 1.0021\nEpoch 70/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.9804\nEpoch 71/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.9434\nEpoch 72/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.9254\nEpoch 73/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.8931\nEpoch 74/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.8458\nEpoch 75/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.8239\nEpoch 76/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.7963\nEpoch 77/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - loss: 0.7619\nEpoch 78/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - loss: 0.7421\nEpoch 79/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.7050\nEpoch 80/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.6655\nEpoch 81/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.6343\nEpoch 82/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.6070\nEpoch 83/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.5859\nEpoch 84/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.5557\nEpoch 85/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.5319\nEpoch 86/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.5154\nEpoch 87/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.4781\nEpoch 88/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.4553\nEpoch 89/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - loss: 0.4317\nEpoch 90/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.4006\nEpoch 91/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.3771\nEpoch 92/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.3597\nEpoch 93/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3410\nEpoch 94/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.3197\nEpoch 95/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.3133\nEpoch 96/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.2975\nEpoch 97/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2847\nEpoch 98/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.2635\nEpoch 99/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2434\nEpoch 100/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - loss: 0.2342\nEpoch 101/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.2166\nEpoch 102/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.2063\nEpoch 103/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1943\nEpoch 104/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1879\nEpoch 105/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1796\nEpoch 106/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1746\nEpoch 107/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.1672\nEpoch 108/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1591\nEpoch 109/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1544\nEpoch 110/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1501\nEpoch 111/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1428\nEpoch 112/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.1358\nEpoch 113/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.1318\nEpoch 114/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1256\nEpoch 115/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1203\nEpoch 116/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1165\nEpoch 117/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.1148\nEpoch 118/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.1095\nEpoch 119/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1047\nEpoch 120/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.1023\nEpoch 121/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.1006\nEpoch 122/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0975\nEpoch 123/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0979\nEpoch 124/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0948\nEpoch 125/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0919\nEpoch 126/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0916\nEpoch 127/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0894\nEpoch 128/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - loss: 0.0869\nEpoch 129/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0843\nEpoch 130/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0839\nEpoch 131/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0811\nEpoch 132/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - loss: 0.0803\nEpoch 133/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0786\nEpoch 134/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0772\nEpoch 135/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - loss: 0.0764\nEpoch 136/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0758\nEpoch 137/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0745\nEpoch 138/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0738\nEpoch 139/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0729\nEpoch 140/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0729\nEpoch 141/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - loss: 0.0715\nEpoch 142/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - loss: 0.0708\nEpoch 143/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0692\nEpoch 144/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - loss: 0.0696\nEpoch 145/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - loss: 0.0683\nEpoch 146/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0664\nEpoch 147/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - loss: 0.0663\nEpoch 148/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - loss: 0.0643\nEpoch 149/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0648\nEpoch 150/150\n\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - loss: 0.0642\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Generate Text","metadata":{}},{"cell_type":"markdown","source":"The function provided by (Bozkurt, 2022b) can then generate text. Unfortunately, my text came out pretty jumbled. My temperature was initially set to 0.5, so I adjusted it to 0.4 and that made a small improvement. In the end, my text still came out jumbled.","metadata":{}},{"cell_type":"code","source":"def generate_text(model, start_string):\n  \n  num_generate = 100\n\n  input_eval = [char2idx[s] for s in start_string]\n  input_eval = tf.expand_dims(input_eval, 0)\n\n  text_generated = []\n\n  temperature = 0.4\n\n  for i in range(num_generate):\n      predictions = model(input_eval)\n    \n      predictions = tf.squeeze(predictions, 0)\n\n      predictions = predictions / temperature\n      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n\n      input_eval = tf.expand_dims([predicted_id], 0)\n\n      text_generated.append(idx2char[predicted_id])\n\n  return (start_string + ''.join(text_generated))","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:33:36.346584Z","iopub.execute_input":"2024-04-08T01:33:36.347263Z","iopub.status.idle":"2024-04-08T01:33:36.354257Z","shell.execute_reply.started":"2024-04-08T01:33:36.347227Z","shell.execute_reply":"2024-04-08T01:33:36.353222Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"inp = \"Life is \"\nprint(generate_text(model, inp))","metadata":{"execution":{"iopub.status.busy":"2024-04-08T01:33:38.580966Z","iopub.execute_input":"2024-04-08T01:33:38.581672Z","iopub.status.idle":"2024-04-08T01:33:39.507669Z","shell.execute_reply.started":"2024-04-08T01:33:38.581627Z","shell.execute_reply":"2024-04-08T01:33:39.506694Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"Life is t ton sin an wo tindis by the by the angore o buth ondinde offes ng te t uno tore be an my o nde as \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# References","metadata":{}},{"cell_type":"markdown","source":"Bozkurt, M. (2022a, October 15). Quotes by philosophers. Kaggle. https://www.kaggle.com/datasets/mertbozkurt5/quotes-by-philosophers/data?select=Arthur-Schopenhauer-Quotes.txt \n\nBozkurt, M. (2022b, October 15). Simple text generation with an RNN. Kaggle. https://www.kaggle.com/code/mertbozkurt5/simple-text-generation-with-an-rnn \n\nGéron, A. (2017). Hands-on machine learning with scikit-learn and tensorflow: Concepts, tools, and techniques to build Intelligent Systems. O’Reilly Media. ","metadata":{}}]}